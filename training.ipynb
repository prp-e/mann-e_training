{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QyvcqeiL65Tj",
        "outputId": "1cc9fc44-0c57-4ec4-ce6a-d71b53f7f435",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mInstalling dependencies...\n",
            "\u001b[1;32mDone, proceed\n"
          ]
        }
      ],
      "source": [
        "#@markdown # Dependencies\n",
        "\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "import os\n",
        "\n",
        "print('\u001b[1;32mInstalling dependencies...')\n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content/\n",
        "    !pip install -qq --no-deps accelerate==0.12.0\n",
        "    !wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/dbdeps.txt\n",
        "    !dpkg -i *.deb\n",
        "    !tar -C / --zstd -xf gcolabdeps.tar.zst\n",
        "    !rm *.deb | rm *.zst | rm *.txt\n",
        "    !git clone -q --depth 1 --branch main https://github.com/TheLastBen/diffusers\n",
        "    !wget -q -O /usr/local/lib/python3.9/dist-packages/flax/core/frozen_dict.py  https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/frozen_dict.py\n",
        "    !pip install gradio==3.16.2 --no-deps -qq  \n",
        "    %env LD_PRELOAD=libtcmalloc.so\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "    os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "\n",
        "print('\u001b[1;32mDone, proceed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3SsbIlxw66N"
      },
      "source": [
        "# Model Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O3KHGKqyeJp9",
        "outputId": "682db0bf-539e-4ccd-9fe8-c83fb0e3dcb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDONE !\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "import wget\n",
        "from subprocess import check_output\n",
        "import urllib.request\n",
        "\n",
        "#@markdown - Skip this cell if you are loading a previous session that contains a trained model.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Model_Version = \"1.5\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
        "\n",
        "#@markdown - Choose which version to finetune.\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd /content/\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Path_to_HuggingFace= \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Load and finetune a model from Hugging Face, use the format \"profile/model\" like : runwayml/stable-diffusion-v1-5\n",
        "#@markdown - If the custom model is private or requires a token, create token.txt containing the token in \"Fast-Dreambooth\" folder in your gdrive.\n",
        "\n",
        "MODEL_PATH = \"\" #@param {type:\"string\"}\n",
        "\n",
        "MODEL_LINK = \"\" #@param {type:\"string\"}\n",
        "\n",
        "safetensors = False #@param {type:\"boolean\"}\n",
        "\n",
        "sftnsr=\"\"\n",
        "if not safetensors:\n",
        "  modelnm=\"model.ckpt\"\n",
        "else:\n",
        "  modelnm=\"model.safetensors\"\n",
        "  sftnsr=\"--from_safetensors\"\n",
        "\n",
        "if os.path.exists('/content/gdrive/MyDrive/Fast-Dreambooth/token.txt'):\n",
        "  with open(\"/content/gdrive/MyDrive/Fast-Dreambooth/token.txt\") as f:\n",
        "     token = f.read()\n",
        "  authe=f'https://USER:{token}@'\n",
        "else:\n",
        "  authe=\"https://\"\n",
        "\n",
        "def downloadmodel():\n",
        "\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "  clear_output()\n",
        "\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v1-5\n",
        "  %cd /content/stable-diffusion-v1-5\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!vae/diffusion_pytorch_model.bin\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "    !wget -q -O vae/diffusion_pytorch_model.bin https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.bin\n",
        "    !rm -r .git\n",
        "    !rm model_index.json\n",
        "    time.sleep(1)    \n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "    %cd /content/\n",
        "    clear_output()\n",
        "    print('\u001b[1;32mDONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "         print('\u001b[1;31mSomething went wrong')\n",
        "         time.sleep(5)\n",
        "\n",
        "def newdownloadmodel():\n",
        "\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v2-768\n",
        "  %cd /content/stable-diffusion-v2-768\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  !rm -r /content/stable-diffusion-v2-768/.git\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  print('\u001b[1;32mDONE !')\n",
        "\n",
        "\n",
        "def newdownloadmodelb():\n",
        "\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v2-512\n",
        "  %cd /content/stable-diffusion-v2-512\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  !rm -r /content/stable-diffusion-v2-512/.git\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  print('\u001b[1;32mDONE !')\n",
        "\n",
        "\n",
        "if Path_to_HuggingFace != \"\":\n",
        "  textenc= f\"{authe}huggingface.co/{Path_to_HuggingFace}/resolve/main/text_encoder/pytorch_model.bin\"\n",
        "  txtenc_size=urllib.request.urlopen(textenc).info().get('Content-Length', None)\n",
        "  if int(txtenc_size)> 670000000 :\n",
        "    if os.path.exists('/content/stable-diffusion-custom'):\n",
        "      !rm -r /content/stable-diffusion-custom\n",
        "    clear_output()\n",
        "    %cd /content/\n",
        "    clear_output()\n",
        "    print(\"\u001b[1;32mV2\")\n",
        "    !mkdir /content/stable-diffusion-custom\n",
        "    %cd /content/stable-diffusion-custom\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"{authe}huggingface.co/{Path_to_HuggingFace}\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "      !rm -r /content/stable-diffusion-custom/.git\n",
        "      %cd /content/ \n",
        "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
        "      clear_output()\n",
        "      print('\u001b[1;32mDONE !')\n",
        "    else:\n",
        "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "            print('\u001b[1;31mCheck the link you provided')\n",
        "            time.sleep(5)\n",
        "  else:\n",
        "    if os.path.exists('/content/stable-diffusion-custom'):\n",
        "      !rm -r /content/stable-diffusion-custom\n",
        "    clear_output()\n",
        "    %cd /content/\n",
        "    clear_output()\n",
        "    print(\"\u001b[1;32mV1\")\n",
        "    !mkdir /content/stable-diffusion-custom\n",
        "    %cd /content/stable-diffusion-custom\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"{authe}huggingface.co/{Path_to_HuggingFace}\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "      !rm -r /content/stable-diffusion-custom/.git\n",
        "      !rm model_index.json\n",
        "      time.sleep(1)\n",
        "      wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "      %cd /content/ \n",
        "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
        "      clear_output()\n",
        "      print('\u001b[1;32mDONE !')\n",
        "    else:\n",
        "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "            print('\u001b[1;31mCheck the link you provided')\n",
        "            time.sleep(5)\n",
        "\n",
        "elif MODEL_PATH !=\"\":\n",
        "  %cd /content\n",
        "  clear_output()\n",
        "  if os.path.exists(str(MODEL_PATH)):\n",
        "    wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
        "    print('\u001b[1;33mDetecting model version...')\n",
        "    Custom_Model_Version=check_output('python det.py '+sftnsr+' --MODEL_PATH '+MODEL_PATH, shell=True).decode('utf-8').replace('\\n', '')\n",
        "    clear_output()\n",
        "    print('\u001b[1;32m'+Custom_Model_Version+' Detected')    \n",
        "    !rm det.py\n",
        "    if Custom_Model_Version=='1.5':      \n",
        "      !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "      !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $MODEL_PATH --dump_path stable-diffusion-custom --original_config_file config.yaml $sftnsr\n",
        "      !rm /content/config.yaml\n",
        "\n",
        "    elif Custom_Model_Version=='V2.1-512px':\n",
        "      !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
        "      !python /content/convertodiff.py \"$MODEL_PATH\" /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n",
        "      !rm /content/convertodiff.py\n",
        "\n",
        "    elif Custom_Model_Version=='V2.1-768px':\n",
        "      !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
        "      !python /content/convertodiff.py \"$MODEL_PATH\" /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n",
        "      !rm /content/convertodiff.py\n",
        "\n",
        "\n",
        "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "      clear_output()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
        "      print('\u001b[1;32mDONE !')\n",
        "    else:\n",
        "      !rm -r /content/stable-diffusion-custom\n",
        "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "        print('\u001b[1;31mConversion error')\n",
        "        time.sleep(5)\n",
        "  else:\n",
        "    while not os.path.exists(str(MODEL_PATH)):\n",
        "       print('\u001b[1;31mWrong path, use the colab file explorer to copy the path')\n",
        "       time.sleep(5)\n",
        "\n",
        "elif MODEL_LINK !=\"\":\n",
        "    %cd /content\n",
        "    clear_output()\n",
        "    !gdown --fuzzy -O $modelnm \"$MODEL_LINK\"\n",
        "    clear_output() \n",
        "    if os.path.exists(modelnm):\n",
        "      if os.path.getsize(modelnm) > 1810671599:\n",
        "        wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
        "        print('\u001b[1;33mDetecting model version...')\n",
        "        Custom_Model_Version=check_output('python det.py '+sftnsr+' --MODEL_PATH '+modelnm, shell=True).decode('utf-8').replace('\\n', '')\n",
        "        clear_output()\n",
        "        print('\u001b[1;32m'+Custom_Model_Version+' Detected') \n",
        "        !rm det.py\n",
        "        if Custom_Model_Version=='1.5':\n",
        "          !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "          !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $modelnm --dump_path stable-diffusion-custom --original_config_file config.yaml $sftnsr\n",
        "          !rm config.yaml\n",
        "\n",
        "        elif Custom_Model_Version=='V2.1-512px':\n",
        "          !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
        "          !python /content/convertodiff.py $modelnm /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n",
        "          !rm convertodiff.py\n",
        "\n",
        "        elif Custom_Model_Version=='V2.1-768px':\n",
        "          !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
        "          !python /content/convertodiff.py $modelnm /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n",
        "          !rm convertodiff.py\n",
        "\n",
        "\n",
        "        if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "          clear_output()\n",
        "          MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
        "          print('\u001b[1;32mDONE !')\n",
        "        else:\n",
        "          !rm -r stable-diffusion-custom\n",
        "          !rm $modelnm\n",
        "          while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "            print('\u001b[1;31mConversion error')\n",
        "            time.sleep(5)\n",
        "      else:\n",
        "        while os.path.getsize(modelnm) < 1810671599:\n",
        "           print('\u001b[1;31mWrong link, check that the link is valid')\n",
        "           time.sleep(5)\n",
        "\n",
        "else:\n",
        "  if Model_Version==\"1.5\":\n",
        "    if not os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "      downloadmodel()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "    else:\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "      print(\"\u001b[1;32mThe v1.5 model already exists, using this model.\")\n",
        "  elif Model_Version==\"V2.1-512px\":\n",
        "    if not os.path.exists('/content/stable-diffusion-v2-512'):\n",
        "      newdownloadmodelb()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n",
        "    else:\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n",
        "      print(\"\u001b[1;32mThe v2-512px model already exists, using this model.\")\n",
        "  elif Model_Version==\"V2.1-768px\":\n",
        "    if not os.path.exists('/content/stable-diffusion-v2-768'):\n",
        "      newdownloadmodel()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n",
        "    else:\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n",
        "      print(\"\u001b[1;32mThe v2-768px model already exists, using this model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tN76Cj5P3RL"
      },
      "source": [
        "# Dreambooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A1B299g-_VJo",
        "outputId": "46b6777c-81a7-4311-c20c-077bf042e87f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mCreating session...\n",
            "\u001b[1;32mSession created, proceed to uploading instance images\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from os import listdir\n",
        "from os.path import isfile\n",
        "from subprocess import check_output\n",
        "import wget\n",
        "import time\n",
        "\n",
        "#@markdown #Create/Load a Session\n",
        "\n",
        "try:\n",
        "  MODEL_NAME\n",
        "  pass\n",
        "except:\n",
        "  MODEL_NAME=\"\"\n",
        "  \n",
        "PT=\"\"\n",
        "\n",
        "Session_Name = \"mann-e_4-2-base\" #@param{type: 'string'}\n",
        "while Session_Name==\"\":\n",
        "  print('\u001b[1;31mInput the Session Name:') \n",
        "  Session_Name=input('')\n",
        "Session_Name=Session_Name.replace(\" \",\"_\")\n",
        "\n",
        "#@markdown - Enter the session name, it if it exists, it will load it, otherwise it'll create an new session.\n",
        "\n",
        "Session_Link_optional = \"\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown - Import a session from another gdrive, the shared gdrive link must point to the specific session's folder that contains the trained CKPT, remove any intermediary CKPT if any.\n",
        "\n",
        "WORKSPACE='/content/gdrive/MyDrive/Fast-Dreambooth'\n",
        "\n",
        "if Session_Link_optional !=\"\":\n",
        "  print('\u001b[1;32mDownloading session...')\n",
        "  with capture.capture_output() as cap:\n",
        "    %cd /content\n",
        "    if not os.path.exists(str(WORKSPACE+'/Sessions')):\n",
        "      %mkdir -p $WORKSPACE'/Sessions'\n",
        "      time.sleep(1)\n",
        "    %cd $WORKSPACE'/Sessions'\n",
        "    !gdown --folder --remaining-ok -O $Session_Name  $Session_Link_optional\n",
        "    %cd $Session_Name\n",
        "    !rm -r instance_images\n",
        "    !unzip instance_images.zip\n",
        "    !rm -r concept_images\n",
        "    !unzip concept_images.zip\n",
        "    !rm -r captions\n",
        "    !unzip captions.zip\n",
        "    %cd /content\n",
        "\n",
        "\n",
        "INSTANCE_NAME=Session_Name\n",
        "OUTPUT_DIR=\"/content/models/\"+Session_Name\n",
        "SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
        "INSTANCE_DIR=SESSION_DIR+'/instance_images'\n",
        "CONCEPT_DIR=SESSION_DIR+'/concept_images'\n",
        "CAPTIONS_DIR=SESSION_DIR+'/captions'\n",
        "MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
        "\n",
        "if os.path.exists(str(SESSION_DIR)):\n",
        "  mdls=[ckpt for ckpt in listdir(SESSION_DIR) if ckpt.split(\".\")[-1]==\"ckpt\"]\n",
        "  if not os.path.exists(MDLPTH) and '.ckpt' in str(mdls):  \n",
        "    \n",
        "    def f(n):\n",
        "      k=0\n",
        "      for i in mdls:\n",
        "        if k==n:\n",
        "          !mv \"$SESSION_DIR/$i\" $MDLPTH\n",
        "        k=k+1\n",
        "\n",
        "    k=0\n",
        "    print('\u001b[1;33mNo final checkpoint model found, select which intermediary checkpoint to use, enter only the number, (000 to skip):\\n\u001b[1;34m')\n",
        "\n",
        "    for i in mdls:\n",
        "      print(str(k)+'- '+i)\n",
        "      k=k+1\n",
        "    n=input()\n",
        "    while int(n)>k-1:\n",
        "      n=input()\n",
        "    if n!=\"000\":\n",
        "      f(int(n))\n",
        "      print('\u001b[1;32mUsing the model '+ mdls[int(n)]+\" ...\")\n",
        "      time.sleep(2)\n",
        "    else:\n",
        "      print('\u001b[1;32mSkipping the intermediary checkpoints.')\n",
        "    del n\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content\n",
        "  resume=False\n",
        "\n",
        "if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n",
        "  print('\u001b[1;32mLoading session with no previous model, using the original model or the custom downloaded model')\n",
        "  if MODEL_NAME==\"\":\n",
        "    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "  else:\n",
        "    print('\u001b[1;32mSession Loaded, proceed to uploading instance images')\n",
        "\n",
        "elif os.path.exists(MDLPTH):\n",
        "  print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "  wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
        "  print('\u001b[1;33mDetecting model version...')\n",
        "  Model_Version=check_output('python det.py --MODEL_PATH '+MDLPTH, shell=True).decode('utf-8').replace('\\n', '')\n",
        "  clear_output()\n",
        "  print('\u001b[1;32m'+Model_Version+' Detected') \n",
        "  !rm det.py  \n",
        "  if Model_Version=='1.5':\n",
        "    !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "    print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "    !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $MDLPTH --dump_path \"$OUTPUT_DIR\" --original_config_file config.yaml\n",
        "    !rm /content/config.yaml\n",
        "\n",
        "  elif Model_Version=='V2.1-512px':\n",
        "    !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
        "    print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1-base\n",
        "    !rm /content/convertodiff.py\n",
        "\n",
        "  elif Model_Version=='V2.1-768px':\n",
        "    !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
        "    print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1\n",
        "    !rm /content/convertodiff.py\n",
        "  \n",
        "  \n",
        "  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "    resume=True\n",
        "    clear_output()\n",
        "    print('\u001b[1;32mSession loaded.')\n",
        "  else:     \n",
        "    if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mConversion error, if the error persists, remove the CKPT file from the current session folder')\n",
        "\n",
        "elif not os.path.exists(str(SESSION_DIR)):\n",
        "    %mkdir -p \"$INSTANCE_DIR\"\n",
        "    print('\u001b[1;32mCreating session...')\n",
        "    if MODEL_NAME==\"\":\n",
        "      print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "    else:\n",
        "      print('\u001b[1;32mSession created, proceed to uploading instance images')\n",
        "\n",
        "    #@markdown\n",
        "\n",
        "    #@markdown # The most important step is to rename the instance pictures of each subject to a unique unknown identifier, example :\n",
        "    #@markdown - If you have 10 pictures of yourself, simply select them all and rename only one to the chosen identifier for example : phtmejhn, the files would be : phtmejhn (1).jpg, phtmejhn (2).png ....etc then upload them, do the same for other people or objects with a different identifier, and that's it.\n",
        "    #@markdown - Checkout this example : https://i.imgur.com/d2lD3rz.jpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c # Link to our dataset files\n",
        "!unzip /content/encoder_data.zip"
      ],
      "metadata": {
        "id": "ivz7_FjZtfq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LC4ukG60fgMy",
        "outputId": "d2ed01d1-ff1b-4400-8a9f-b2da45bd9d8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  |███████████████| 720/720 Uploaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1;32mDone, proceed to the next cell\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "import time\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "import wget\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content\n",
        "  if not os.path.exists(\"/content/smart_crop.py\"):\n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/smart_crop.py')\n",
        "  from smart_crop import *\n",
        "\n",
        "#@markdown #Instance Images\n",
        "#@markdown ----\n",
        "\n",
        "#@markdown\n",
        "#@markdown - Run the cell to upload the instance pictures.\n",
        "#@markdown - You can add `external captions` in txt files by simply giving each txt file the same name as the instance image, for example dikgur (1).jpg and dikgur (1).txt, and upload them here, to use the external captions, check the box \"external_captions\" in the training cell. `All the images must have one same extension` jpg or png or....etc\n",
        "\n",
        "Remove_existing_instance_images= True #@param{type: 'boolean'}\n",
        "#@markdown - Uncheck the box to keep the existing instance images.\n",
        "\n",
        "if Remove_existing_instance_images:\n",
        "  if os.path.exists(str(INSTANCE_DIR)):\n",
        "    !rm -r \"$INSTANCE_DIR\"\n",
        "  if os.path.exists(str(CAPTIONS_DIR)):\n",
        "    !rm -r \"$CAPTIONS_DIR\"\n",
        "\n",
        "if not os.path.exists(str(INSTANCE_DIR)):\n",
        "  %mkdir -p \"$INSTANCE_DIR\"\n",
        "if not os.path.exists(str(CAPTIONS_DIR)):\n",
        "  %mkdir -p \"$CAPTIONS_DIR\"\n",
        "\n",
        "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "\n",
        "IMAGES_FOLDER_OPTIONAL=\"/content/encoder_data\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown - If you prefer to specify directly the folder of the pictures instead of uploading, this will add the pictures to the existing (if any) instance images. Leave EMPTY to upload.\n",
        "\n",
        "Smart_Crop_images= False #@param{type: 'boolean'}\n",
        "Crop_size = 512 #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"] {type:\"raw\"}\n",
        "\n",
        "#@markdown - Smart crop the images without manual intervention.\n",
        "\n",
        "while IMAGES_FOLDER_OPTIONAL !=\"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n",
        "  print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path :')\n",
        "  IMAGES_FOLDER_OPTIONAL=input('')\n",
        "\n",
        "if IMAGES_FOLDER_OPTIONAL!=\"\":\n",
        "  if os.path.exists(IMAGES_FOLDER_OPTIONAL+\"/.ipynb_checkpoints\"):\n",
        "    %rm -r \"$IMAGES_FOLDER_OPTIONAL\"\"/.ipynb_checkpoints\"\n",
        "\n",
        "  with capture.capture_output() as cap:\n",
        "    !mv $IMAGES_FOLDER_OPTIONAL/*.txt $CAPTIONS_DIR\n",
        "  if Smart_Crop_images:\n",
        "    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      extension = filename.split(\".\")[-1]\n",
        "      identifier=filename.split(\".\")[0]\n",
        "      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n",
        "      file = Image.open(IMAGES_FOLDER_OPTIONAL+\"/\"+filename)\n",
        "      width, height = file.size\n",
        "      if file.size !=(Crop_size, Crop_size):\n",
        "        image=crop_image(file, Crop_size)\n",
        "        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n",
        "            image[0] = image[0].convert(\"RGB\")\n",
        "            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n",
        "        else:\n",
        "            image[0].save(new_path_with_file, format=extension.upper())\n",
        "      else:\n",
        "        !cp \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n",
        "\n",
        "  else:\n",
        "    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      %cp -r \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n",
        "\n",
        "  print('\\n\u001b[1;32mDone, proceed to the next cell')\n",
        "\n",
        "\n",
        "elif IMAGES_FOLDER_OPTIONAL ==\"\":\n",
        "  up=\"\"\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    if filename.split(\".\")[-1]==\"txt\":\n",
        "      shutil.move(filename, CAPTIONS_DIR)\n",
        "    up=[filename for filename in uploaded.keys() if filename.split(\".\")[-1]!=\"txt\"]\n",
        "  if Smart_Crop_images:\n",
        "    for filename in tqdm(up, bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      shutil.move(filename, INSTANCE_DIR)\n",
        "      extension = filename.split(\".\")[-1]\n",
        "      identifier=filename.split(\".\")[0]\n",
        "      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n",
        "      file = Image.open(new_path_with_file)\n",
        "      width, height = file.size\n",
        "      if file.size !=(Crop_size, Crop_size):\n",
        "        image=crop_image(file, Crop_size)\n",
        "        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n",
        "            image[0] = image[0].convert(\"RGB\")\n",
        "            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n",
        "        else:\n",
        "            image[0].save(new_path_with_file, format=extension.upper())\n",
        "      clear_output()\n",
        "  else:\n",
        "    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      shutil.move(filename, INSTANCE_DIR)\n",
        "      clear_output()\n",
        "  print('\\n\u001b[1;32mDone, proceed to the next cell')\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd \"$INSTANCE_DIR\"\n",
        "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "  %cd \"$CAPTIONS_DIR\"\n",
        "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "  \n",
        "  %cd $SESSION_DIR\n",
        "  !rm instance_images.zip captions.zip\n",
        "  !zip -r instance_images instance_images\n",
        "  !zip -r captions captions\n",
        "  %cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Baw78R-w4T2j",
        "outputId": "1486cf1c-8da5-4378-ec2e-f78cdc1272f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443,
          "referenced_widgets": [
            "92bd5902e16a469d84560bfe10fbd2ce",
            "8a049329329c4338be6194022a1f64a7",
            "6c799f0085124daea6caaeaf5663873b",
            "42e771e595264165b55c50649e2220a5",
            "8128c5e87ae14566a280a8f42f4d161c",
            "3e7591611fc24547a2cf425ea3535518",
            "fc94b23c6b4f4bb9b310f012906f3f98",
            "1fbf0748bf6f4e5c91d76a126bf20524",
            "7c1c239ee37945aca6d13603db342dc6",
            "8f8454aad91849c7a9b6f48dc11feb50",
            "22952f1215544894a26b432c2e6e1938",
            "8be8320ec1ce4e13948da5be8960fc43",
            "15353aa966ed42a488be72cf492126ae",
            "86f5167171954257839f072f76c6af03",
            "d68e8e0856f64ddb8d0127655303dce2",
            "87de9d3a49f545758839639b715f3427",
            "b7203004fa6f4037aff09238b1e02b92",
            "ebe762e1d8d844a4b9bb991b7c6d0baa",
            "fe97ec72454b4f8f910cbc4fbefbed5f"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Select(options=('Select an instance image to caption', 'mstyle-0317.png', 'mstyle-0370.png', 'm…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92bd5902e16a469d84560bfe10fbd2ce"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from io import BytesIO\n",
        "#@markdown #Captions\n",
        "\n",
        "#@markdown - Open a tool to manually `create` captions or edit existing captions of the instance images.\n",
        "\n",
        "paths=\"\"\n",
        "out=\"\"\n",
        "widgets_l=\"\"\n",
        "clear_output()\n",
        "def Caption(path):\n",
        "    if path!=\"Select an instance image to caption\":\n",
        "      \n",
        "      name = os.path.splitext(os.path.basename(path))[0]\n",
        "      ext=os.path.splitext(os.path.basename(path))[-1][1:]\n",
        "      if ext==\"jpg\" or \"JPG\":\n",
        "        ext=\"JPEG\"      \n",
        "\n",
        "      if os.path.exists(CAPTIONS_DIR+\"/\"+name + '.txt'):\n",
        "        with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'r') as f:\n",
        "            text = f.read()\n",
        "      else:\n",
        "        with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'w') as f:\n",
        "            f.write(\"\")\n",
        "            with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'r') as f:\n",
        "                text = f.read()   \n",
        "\n",
        "      img=Image.open(os.path.join(INSTANCE_DIR,path))\n",
        "      img=img.convert(\"RGB\")\n",
        "      img=img.resize((420, 420))\n",
        "      image_bytes = BytesIO()\n",
        "      img.save(image_bytes, format=ext, qualiy=10)\n",
        "      image_bytes.seek(0)\n",
        "      image_data = image_bytes.read()\n",
        "      img= image_data  \n",
        "      image = widgets.Image(\n",
        "          value=img,\n",
        "          width=420,\n",
        "          height=420\n",
        "      )\n",
        "      text_area = widgets.Textarea(value=text, description='', disabled=False, layout={'width': '300px', 'height': '120px'})\n",
        "      \n",
        "\n",
        "      def update_text(text):\n",
        "          with open(CAPTIONS_DIR+\"/\"+name + '.txt', 'w') as f:\n",
        "              f.write(text)\n",
        "\n",
        "      button = widgets.Button(description='Save', button_style='success')\n",
        "      button.on_click(lambda b: update_text(text_area.value))\n",
        "\n",
        "      return widgets.VBox([widgets.HBox([image, text_area, button])])\n",
        "\n",
        "\n",
        "paths = os.listdir(INSTANCE_DIR)\n",
        "widgets_l = widgets.Select(options=[\"Select an instance image to caption\"]+paths, rows=25)\n",
        "\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def click(change):\n",
        "    with out:\n",
        "        out.clear_output()\n",
        "        display(Caption(change.new))\n",
        "\n",
        "widgets_l.observe(click, names='value')\n",
        "display(widgets.HBox([widgets_l, out]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmQYfZilzY6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1-9QbkfAVYYU",
        "outputId": "61011cbe-740c-45b2-b0be-b5a56625baae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #Start DreamBooth\n",
        "#@markdown ---\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from google.colab import runtime\n",
        "import time\n",
        "import random\n",
        "\n",
        "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "if os.path.exists(CONCEPT_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $CONCEPT_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "if os.path.exists(CAPTIONS_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $CAPTIONS_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "Resume_Training = False #@param {type:\"boolean\"}\n",
        "\n",
        "if resume and not Resume_Training:\n",
        "  print('\u001b[1;31mOverwrite your previously trained model ? answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001b[0m')\n",
        "  while True:\n",
        "    ansres=input('')\n",
        "    if ansres=='no':\n",
        "      Resume_Training = True\n",
        "      break\n",
        "    elif ansres=='yes':\n",
        "      Resume_Training = False\n",
        "      resume= False\n",
        "      break\n",
        "\n",
        "while not Resume_Training and MODEL_NAME==\"\":\n",
        "  print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "  time.sleep(5)\n",
        "\n",
        "#@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n",
        "\n",
        "MODELT_NAME=MODEL_NAME\n",
        "\n",
        "UNet_Training_Steps=16000 #@param{type: 'number'}\n",
        "UNet_Learning_Rate = 2e-6 #@param [\"2e-5\",\"1e-5\",\"9e-6\",\"8e-6\",\"7e-6\",\"6e-6\",\"5e-6\", \"4e-6\", \"3e-6\", \"2e-6\"] {type:\"raw\"}\n",
        "untlr=UNet_Learning_Rate\n",
        "\n",
        "#@markdown - These default settings are for a dataset of 10 pictures which is enough for training a face, start with 1500 or lower, test the model, if not enough, resume training for 200 steps, keep testing until you get the desired output, `set it to 0 to train only the text_encoder`.\n",
        "\n",
        "Text_Encoder_Training_Steps=1440 #@param{type: 'number'}\n",
        "\n",
        "#@markdown - 200-450 steps is enough for a small dataset, keep this number small to avoid overfitting, set to 0 to disable, `set it to 0 before resuming training if it is already trained`.\n",
        "\n",
        "Text_Encoder_Learning_Rate = 1e-6 #@param [\"2e-6\", \"1e-6\",\"8e-7\",\"6e-7\",\"5e-7\",\"4e-7\"] {type:\"raw\"}\n",
        "txlr=Text_Encoder_Learning_Rate\n",
        "\n",
        "#@markdown - Learning rate for both text_encoder and concept_text_encoder, keep it low to avoid overfitting (1e-6 is higher than 4e-7)\n",
        "\n",
        "Text_Encoder_Concept_Training_Steps=0 #@param{type: 'number'}\n",
        "\n",
        "#@markdown - Suitable for training a style/concept as it acts as heavy regularization, set it to 1500 steps for 200 concept images (you can go higher), set to 0 to disable, set both the settings above to 0 to fintune only the text_encoder on the concept, `set it to 0 before resuming training if it is already trained`.\n",
        "\n",
        "trnonltxt=\"\"\n",
        "if UNet_Training_Steps==0:\n",
        "   trnonltxt=\"--train_only_text_encoder\"\n",
        "\n",
        "Seed=''\n",
        "\n",
        "ofstnse=\"\"\n",
        "Offset_Noise = False #@param {type:\"boolean\"}\n",
        "#@markdown - Always use it for style training.\n",
        "\n",
        "if Offset_Noise:\n",
        "  ofstnse=\"--offset_noise\"\n",
        "\n",
        "External_Captions = False #@param {type:\"boolean\"}\n",
        "#@markdown - Get the captions from a text file for each instance image.\n",
        "extrnlcptn=\"\"\n",
        "if External_Captions:\n",
        "  extrnlcptn=\"--external_captions\"\n",
        "\n",
        "Resolution = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
        "Res=int(Resolution)\n",
        "\n",
        "#@markdown - Higher resolution = Higher quality, make sure the instance images are cropped to this selected size (or larger).\n",
        "\n",
        "fp16 = True\n",
        "\n",
        "if Seed =='' or Seed=='0':\n",
        "  Seed=random.randint(1, 999999)\n",
        "else:\n",
        "  Seed=int(Seed)\n",
        "\n",
        "if fp16:\n",
        "  prec=\"fp16\"\n",
        "else:\n",
        "  prec=\"no\"\n",
        "\n",
        "precision=prec\n",
        "\n",
        "resuming=\"\"\n",
        "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=OUTPUT_DIR\n",
        "  print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "  resuming=\"Yes\"\n",
        "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m')\n",
        "  MODELT_NAME=MODEL_NAME\n",
        "  while MODEL_NAME==\"\":\n",
        "    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
        "    time.sleep(5)\n",
        "\n",
        "Enable_text_encoder_training= True\n",
        "Enable_Text_Encoder_Concept_Training= True\n",
        "\n",
        "if Text_Encoder_Training_Steps==0 :\n",
        "   Enable_text_encoder_training= False\n",
        "else:\n",
        "  stptxt=Text_Encoder_Training_Steps\n",
        "\n",
        "if Text_Encoder_Concept_Training_Steps==0:\n",
        "   Enable_Text_Encoder_Concept_Training= False\n",
        "else:\n",
        "  stptxtc=Text_Encoder_Concept_Training_Steps\n",
        "\n",
        "#@markdown ---------------------------\n",
        "Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
        "Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
        "if Save_Checkpoint_Every==None:\n",
        "  Save_Checkpoint_Every=1\n",
        "#@markdown - Minimum 200 steps between each save.\n",
        "stp=0\n",
        "Start_saving_from_the_step=500 #@param{type: 'number'}\n",
        "if Start_saving_from_the_step==None:\n",
        "  Start_saving_from_the_step=0\n",
        "if (Start_saving_from_the_step < 200):\n",
        "  Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "stpsv=Start_saving_from_the_step\n",
        "if Save_Checkpoint_Every_n_Steps:\n",
        "  stp=Save_Checkpoint_Every\n",
        "#@markdown - Start saving intermediary checkpoints from this step.\n",
        "\n",
        "Disconnect_after_training=False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown - Auto-disconnect from google colab after the training to avoid wasting compute units.\n",
        "\n",
        "def dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "    \n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $trnonltxt \\\n",
        "    $extrnlcptn \\\n",
        "    $ofstnse \\\n",
        "    --image_captions_filename \\\n",
        "    --train_text_encoder \\\n",
        "    --dump_only_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$txlr \\\n",
        "    --lr_scheduler=\"linear\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "def train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps):\n",
        "    clear_output()\n",
        "    if resuming==\"Yes\":\n",
        "      print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "    print('\u001b[1;33mTraining the UNet...\u001b[0m')\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $extrnlcptn \\\n",
        "    $ofstnse \\\n",
        "    --image_captions_filename \\\n",
        "    --train_only_unet \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --Session_dir=$SESSION_DIR \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$untlr \\\n",
        "    --lr_scheduler=\"linear\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "\n",
        "if Enable_text_encoder_training :\n",
        "  print('\u001b[1;33mTraining the text encoder...\u001b[0m')\n",
        "  if os.path.exists(OUTPUT_DIR+'/'+'text_encoder_trained'):\n",
        "    %rm -r $OUTPUT_DIR\"/text_encoder_trained\"\n",
        "  dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
        "\n",
        "if Enable_Text_Encoder_Concept_Training:\n",
        "  if os.path.exists(CONCEPT_DIR):\n",
        "    if os.listdir(CONCEPT_DIR)!=[]:\n",
        "      clear_output()\n",
        "      if resuming==\"Yes\":\n",
        "        print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "      print('\u001b[1;33mTraining the text encoder on the concept...\u001b[0m')\n",
        "      dump_only_textenc(trnonltxt, MODELT_NAME, CONCEPT_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxtc)\n",
        "    else:\n",
        "      clear_output()\n",
        "      if resuming==\"Yes\":\n",
        "        print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "      print('\u001b[1;31mNo concept images found, skipping concept training...')\n",
        "      Text_Encoder_Concept_Training_Steps=0\n",
        "      time.sleep(8)\n",
        "  else:\n",
        "      clear_output()\n",
        "      if resuming==\"Yes\":\n",
        "        print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "      print('\u001b[1;31mNo concept images found, skipping concept training...')\n",
        "      Text_Encoder_Concept_Training_Steps=0\n",
        "      time.sleep(8)\n",
        "\n",
        "if UNet_Training_Steps!=0:\n",
        "  train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps=UNet_Training_Steps)\n",
        "\n",
        "if UNet_Training_Steps==0 and Text_Encoder_Concept_Training_Steps==0 and Text_Encoder_Training_Steps==0 :\n",
        "  print('\u001b[1;32mNothing to do')\n",
        "else:\n",
        "  if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "    prc=\"--fp16\" if precision==\"fp16\" else \"\"\n",
        "    !python /content/diffusers/scripts/convertosdv2.py $prc $OUTPUT_DIR $SESSION_DIR/$Session_Name\".ckpt\"\n",
        "    clear_output()\n",
        "    if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "      clear_output()\n",
        "      print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\")\n",
        "      if Disconnect_after_training :\n",
        "        time.sleep(20)\n",
        "        runtime.unassign()\n",
        "    else:\n",
        "      print(\"\u001b[1;31mSomething went wrong\")\n",
        "  else:\n",
        "    print(\"\u001b[1;31mSomething went wrong\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehi1KKs-l-ZS"
      },
      "source": [
        "# Test The Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iAZGngFcI8hq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import sys\n",
        "import fileinput\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "\n",
        "Previous_Session=\"\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown - Leave empty if you want to use the current trained model.\n",
        "\n",
        "Use_Custom_Path = False #@param {type:\"boolean\"}\n",
        "\n",
        "try:\n",
        "  INSTANCE_NAME\n",
        "  INSTANCET=INSTANCE_NAME\n",
        "except:\n",
        "  pass\n",
        "#@markdown - if checked, an input box will ask the full path to a desired model.\n",
        "\n",
        "if Previous_Session!=\"\":\n",
        "  INSTANCET=Previous_Session\n",
        "  INSTANCET=INSTANCET.replace(\" \",\"_\")\n",
        "\n",
        "if Use_Custom_Path:\n",
        "  try:\n",
        "    INSTANCET\n",
        "    del INSTANCET\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "  INSTANCET\n",
        "  if Previous_Session!=\"\":\n",
        "    path_to_trained_model='/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/'+Previous_Session+\"/\"+Previous_Session+'.ckpt'\n",
        "  else:\n",
        "    path_to_trained_model=SESSION_DIR+\"/\"+INSTANCET+'.ckpt'\n",
        "except:\n",
        "  print('\u001b[1;31mIt seems that you did not perform training during this session \u001b[1;32mor you chose to use a custom path,\\nprovide the full path to the model (including the name of the model):\\n')\n",
        "  path_to_trained_model=input()\n",
        "     \n",
        "while not os.path.exists(path_to_trained_model):\n",
        "   print(\"\u001b[1;31mThe model doesn't exist on you Gdrive, use the file explorer to get the path : \")\n",
        "   path_to_trained_model=input()\n",
        "   \n",
        "fgitclone = \"git clone --depth 1\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    if not os.path.exists('/content/gdrive/MyDrive'):\n",
        "      !mkdir -p /content/gdrive/MyDrive\n",
        "\n",
        "if not os.path.exists('/content/gdrive/MyDrive/sd/stablediffusion'):\n",
        "    !wget -q -O /content/sd_rep.tar.zst https://huggingface.co/TheLastBen/dependencies/resolve/main/sd_rep.tar.zst\n",
        "    !tar -C  /content/gdrive/MyDrive --zstd -xf /content/sd_rep.tar.zst\n",
        "    !rm /content/sd_rep.tar.zst\n",
        "    clear_output()\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/MyDrive/sd\n",
        "  !git clone -q --branch master https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "  %cd stable-diffusion-webui\n",
        "  !mkdir cache\n",
        "  !sed -i 's@~/.cache@/content/gdrive/MyDrive/sd/stable-diffusion-webui/cache@' /usr/local/lib/python3.9/dist-packages/transformers/utils/hub.py\n",
        "\n",
        "  clear_output()\n",
        "  !git reset --hard\n",
        "  time.sleep(1)\n",
        "  !rm webui.sh\n",
        "  !git pull\n",
        "  !git fetch --unshallow\n",
        "  !git checkout a9eab236d7e8afa4d6205127904a385b2c43bb24\n",
        "  \n",
        "with capture.capture_output() as cap:\n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "Ngrok_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Input your ngrok token if you want to use ngrok server.\n",
        "\n",
        "Use_localtunnel = False #@param {type:\"boolean\"}\n",
        "\n",
        "User = \"\" #@param {type:\"string\"}\n",
        "Password= \"\" #@param {type:\"string\"}\n",
        "#@markdown - Add credentials to your Gradio interface (optional).\n",
        "\n",
        "auth=f\"--gradio-auth {User}:{Password}\"\n",
        "if User ==\"\" or Password==\"\":\n",
        "  auth=\"\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd modules\n",
        "  !wget -q -O paths.py https://github.com/TheLastBen/fast-stable-diffusion/raw/5632d2ef7fffd940976538d270854ec4faf26855/AUTOMATIC1111_files/paths.py\n",
        "  !wget -q -O extras.py https://github.com/AUTOMATIC1111/stable-diffusion-webui/raw/a9eab236d7e8afa4d6205127904a385b2c43bb24/modules/extras.py\n",
        "  !wget -q -O sd_models.py https://github.com/AUTOMATIC1111/stable-diffusion-webui/raw/a9eab236d7e8afa4d6205127904a385b2c43bb24/modules/sd_models.py\n",
        "  !wget -q -O /usr/local/lib/python3.9/dist-packages/gradio/blocks.py https://github.com/TheLastBen/fast-stable-diffusion/raw/7ff88eaa1fb4997bacd9845bd487f9a14335d625/AUTOMATIC1111_files/blocks.py\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "\n",
        "  !sed -i \"s@os.path.splitext(checkpoint_file)@os.path.splitext(checkpoint_file); map_location='cuda'@\" /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/sd_models.py\n",
        "  !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py\n",
        "  !sed -i \"s@map_location='cpu'@map_location='cuda'@\" /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/extras.py\n",
        "  !sed -i 's@print(\\\"No module.*@@' /content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/model.py\n",
        "  !sed -i 's@\\\"quicksettings\\\": OptionInfo(.*@\"quicksettings\": OptionInfo(\"sd_model_checkpoint,  sd_vae, CLIP_stop_at_last_layers, inpainting_mask_weight, initial_noise_multiplier\", \"Quicksettings list\"),@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/shared.py\n",
        "\n",
        "share=''\n",
        "if Ngrok_token!=\"\":\n",
        "  ngrok.kill()\n",
        "  srv=ngrok.connect(7860, pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token) , bind_tls=True).public_url\n",
        "\n",
        "  for line in fileinput.input('/usr/local/lib/python3.9/dist-packages/gradio/blocks.py', inplace=True):\n",
        "    if line.strip().startswith('self.server_name ='):\n",
        "        line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "    if line.strip().startswith('self.protocol = \"https\"'):\n",
        "        line = '            self.protocol = \"https\"\\n'\n",
        "    if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "        line = ''\n",
        "    if line.strip().startswith('else \"http\"'):\n",
        "        line = ''\n",
        "    sys.stdout.write(line)\n",
        "\n",
        "elif Use_localtunnel:\n",
        "  with capture.capture_output() as cap:\n",
        "    share=''\n",
        "    %cd /content\n",
        "    !nohup lt --port 7860 > srv.txt 2>&1 &\n",
        "    time.sleep(2)\n",
        "    !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
        "    time.sleep(2)\n",
        "    srv= getoutput('cat /content/srvr.txt')\n",
        "\n",
        "    for line in fileinput.input('/usr/local/lib/python3.9/dist-packages/gradio/blocks.py', inplace=True):\n",
        "      if line.strip().startswith('self.server_name ='):\n",
        "          line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "      if line.strip().startswith('self.protocol = \"https\"'):\n",
        "          line = '            self.protocol = \"https\"\\n'\n",
        "      if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "          line = ''\n",
        "      if line.strip().startswith('else \"http\"'):\n",
        "          line = ''\n",
        "      sys.stdout.write(line)\n",
        "            \n",
        "    !rm /content/srv.txt /content/srvr.txt\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
        "\n",
        "else:\n",
        "  share='--share'\n",
        "\n",
        "configf=\"--api --disable-safe-unpickle --enable-insecure-extension-access --no-half-vae --opt-sdp-attention --no-download-sd-model --disable-console-progressbars\"\n",
        "\n",
        "clear_output()\n",
        "\n",
        "if os.path.isfile(path_to_trained_model):\n",
        "  !python /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share --ckpt \"$path_to_trained_model\" $auth $configf\n",
        "else:\n",
        "  !python /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share --ckpt-dir \"$path_to_trained_model\" $auth $configf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_mQ23XsOc5R"
      },
      "source": [
        "# Upload The Trained Model to Hugging Face "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NTqUIuhROdH4"
      },
      "outputs": [],
      "source": [
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "Upload_sample_images = False #@param {type:\"boolean\"}\n",
        "#@markdown - Upload showcase images of your trained model\n",
        "\n",
        "Name_of_your_concept = \"\" #@param {type:\"string\"}\n",
        "if(Name_of_your_concept == \"\"):\n",
        "  Name_of_your_concept = Session_Name\n",
        "Name_of_your_concept=Name_of_your_concept.replace(\" \",\"-\")  \n",
        "  \n",
        "#@markdown - [Create a write access token](https://huggingface.co/settings/tokens) , go to \"New token\" -> Role : Write. A regular read token won't work here.\n",
        "hf_token_write = \"\" #@param {type:\"string\"}\n",
        "if hf_token_write ==\"\":\n",
        "  print('\u001b[1;32mYour Hugging Face write access token : ')\n",
        "  hf_token_write=input()\n",
        "\n",
        "hf_token = hf_token_write\n",
        "\n",
        "api = HfApi()\n",
        "your_username = api.whoami(token=hf_token)[\"name\"]\n",
        "\n",
        "repo_id = f\"{your_username}/{slugify(Name_of_your_concept)}\"\n",
        "output_dir = f'/content/models/'+INSTANCE_NAME\n",
        "\n",
        "def bar(prg):\n",
        "    br=\"\u001b[1;33mUploading to HuggingFace : \" '\u001b[0m|'+'█' * prg + ' ' * (25-prg)+'| ' +str(prg*4)+ \"%\"\n",
        "    return br\n",
        "\n",
        "print(\"\u001b[1;32mLoading...\")\n",
        "\n",
        "NM=\"False\"\n",
        "if os.path.getsize(OUTPUT_DIR+\"/text_encoder/pytorch_model.bin\") > 670901463:\n",
        "  NM=\"True\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  if NM==\"False\":\n",
        "    %cd $OUTPUT_DIR\n",
        "    !rm -r safety_checker feature_extractor .git\n",
        "    !rm model_index.json\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"https://USER:{hf_token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"feature_extractor\\nsafety_checker\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    !rm -r .git\n",
        "    %cd /content\n",
        "  else:\n",
        "    %cd $OUTPUT_DIR\n",
        "    !rm -r feature_extractor .git\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"https://USER:{hf_token}@huggingface.co/stabilityai/stable-diffusion-2-1\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"feature_extractor\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    !rm -r .git\n",
        "    %cd /content\n",
        "\n",
        "\n",
        "image_string = \"\"\n",
        "\n",
        "if os.path.exists('/content/sample_images'):\n",
        "  !rm -r /content/sample_images\n",
        "Samples=\"/content/sample_images\"\n",
        "!mkdir $Samples\n",
        "clear_output()\n",
        "\n",
        "if Upload_sample_images:\n",
        "\n",
        "  print(\"\u001b[1;32mUpload Sample images of the model\")\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    shutil.move(filename, Samples)\n",
        "  %cd $Samples\n",
        "  !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
        "  %cd /content\n",
        "  clear_output()\n",
        "\n",
        "  print(bar(1))\n",
        "\n",
        "  images_upload = os.listdir(Samples)\n",
        "  instance_prompt_list = []\n",
        "  for i, image in enumerate(images_upload):\n",
        "      image_string = f'''\n",
        "  {image_string}![{i}](https://huggingface.co/{repo_id}/resolve/main/sample_images/{image})\n",
        "      '''\n",
        "    \n",
        "readme_text = f'''---\n",
        "license: creativeml-openrail-m\n",
        "tags:\n",
        "- text-to-image\n",
        "- stable-diffusion\n",
        "---\n",
        "### {Name_of_your_concept} Dreambooth model trained by {api.whoami(token=hf_token)[\"name\"]} with [TheLastBen's fast-DreamBooth](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb) notebook\n",
        "\n",
        "\n",
        "Test the concept via A1111 Colab [fast-Colab-A1111](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast_stable_diffusion_AUTOMATIC1111.ipynb)\n",
        "\n",
        "Sample pictures of this concept:\n",
        "{image_string}\n",
        "'''\n",
        "#Save the readme to a file\n",
        "readme_file = open(\"README.md\", \"w\")\n",
        "readme_file.write(readme_text)\n",
        "readme_file.close()\n",
        "\n",
        "operations = [\n",
        "  CommitOperationAdd(path_in_repo=\"README.md\", path_or_fileobj=\"README.md\"),\n",
        "  CommitOperationAdd(path_in_repo=f\"{Session_Name}.ckpt\",path_or_fileobj=MDLPTH)\n",
        "\n",
        "]\n",
        "create_repo(repo_id,private=True, token=hf_token)\n",
        "\n",
        "api.create_commit(\n",
        "  repo_id=repo_id,\n",
        "  operations=operations,\n",
        "  commit_message=f\"Upload the concept {Name_of_your_concept} embeds and token\",\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path=OUTPUT_DIR+\"/feature_extractor\",\n",
        "  path_in_repo=\"feature_extractor\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(4))\n",
        "\n",
        "if NM==\"False\":\n",
        "  api.upload_folder(\n",
        "    folder_path=OUTPUT_DIR+\"/safety_checker\",\n",
        "    path_in_repo=\"safety_checker\",\n",
        "    repo_id=repo_id,\n",
        "    token=hf_token\n",
        "  )\n",
        "\n",
        "clear_output()\n",
        "print(bar(8))\n",
        "\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path=OUTPUT_DIR+\"/scheduler\",\n",
        "  path_in_repo=\"scheduler\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(9))\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path=OUTPUT_DIR+\"/text_encoder\",\n",
        "  path_in_repo=\"text_encoder\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(12))\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path=OUTPUT_DIR+\"/tokenizer\",\n",
        "  path_in_repo=\"tokenizer\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(13))\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path=OUTPUT_DIR+\"/unet\",\n",
        "  path_in_repo=\"unet\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(21))\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path=OUTPUT_DIR+\"/vae\",\n",
        "  path_in_repo=\"vae\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(23))\n",
        "\n",
        "api.upload_file(\n",
        "  path_or_fileobj=OUTPUT_DIR+\"/model_index.json\",\n",
        "  path_in_repo=\"model_index.json\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(24))\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path=Samples,\n",
        "  path_in_repo=\"sample_images\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(25))\n",
        "\n",
        "display_markdown(f'''## Your concept was saved successfully. [Click here to access it](https://huggingface.co/{repo_id})\n",
        "''', raw=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "92bd5902e16a469d84560bfe10fbd2ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a049329329c4338be6194022a1f64a7",
              "IPY_MODEL_6c799f0085124daea6caaeaf5663873b"
            ],
            "layout": "IPY_MODEL_42e771e595264165b55c50649e2220a5"
          }
        },
        "8a049329329c4338be6194022a1f64a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SelectModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SelectModel",
            "_options_labels": [
              "Select an instance image to caption",
              "mstyle-0317.png",
              "mstyle-0370.png",
              "mstyle-0270.png",
              "mstyle-0297.png",
              "mstyle-0241.png",
              "mstyle-0393.png",
              "mstyle-0222.png",
              "mstyle-0067.png",
              "mstyle-0589.png",
              "mstyle-0120.png",
              "mstyle-0716.png",
              "mstyle-0573.png",
              "mstyle-0345.png",
              "mstyle-0403.png",
              "mstyle-0700.png",
              "mstyle-0112.png",
              "mstyle-0180.png",
              "mstyle-0395.png",
              "mstyle-0539.png",
              "mstyle-0402.png",
              "mstyle-0611.png",
              "mstyle-0595.png",
              "mstyle-0119.png",
              "mstyle-0412.png",
              "mstyle-0046.png",
              "mstyle-0552.png",
              "mstyle-0439.png",
              "mstyle-0108.png",
              "mstyle-0000.png",
              "mstyle-0478.png",
              "mstyle-0656.png",
              "mstyle-0536.png",
              "mstyle-0347.png",
              "mstyle-0707.png",
              "mstyle-0325.png",
              "mstyle-0117.png",
              "mstyle-0419.png",
              "mstyle-0677.png",
              "mstyle-0455.png",
              "mstyle-0505.png",
              "mstyle-0690.png",
              "mstyle-00105.png",
              "mstyle-0069.png",
              "mstyle-0642.png",
              "mstyle-0684.png",
              "mstyle-0145.png",
              "mstyle-0200.png",
              "mstyle-0201.png",
              "mstyle-0146.png",
              "mstyle-0152.png",
              "mstyle-0301.png",
              "mstyle-0468.png",
              "mstyle-0714.png",
              "mstyle-0471.png",
              "mstyle-0218.png",
              "mstyle-0239.png",
              "mstyle-0008.png",
              "mstyle-0592.png",
              "mstyle-0501.png",
              "mstyle-0125.png",
              "mstyle-0251.png",
              "mstyle-0450.png",
              "mstyle-0121.png",
              "mstyle-0102.png",
              "mstyle-0183.png",
              "mstyle-0469.png",
              "mstyle-0074.png",
              "mstyle-0541.png",
              "mstyle-0438.png",
              "mstyle-0266.png",
              "mstyle-0107.png",
              "mstyle-0509.png",
              "mstyle-0322.png",
              "mstyle-0517.png",
              "mstyle-0711.png",
              "mstyle-0720.png",
              "mstyle-0485.png",
              "mstyle-0118.png",
              "mstyle-0185.png",
              "mstyle-0357.png",
              "mstyle-0272.png",
              "mstyle-0390.png",
              "mstyle-0378.png",
              "mstyle-0596.png",
              "mstyle-0563.png",
              "mstyle-0099.png",
              "mstyle-0238.png",
              "mstyle-0092.png",
              "mstyle-0336.png",
              "mstyle-0629.png",
              "mstyle-0600.png",
              "mstyle-0535.png",
              "mstyle-0016.png",
              "mstyle-0133.png",
              "mstyle-0171.png",
              "mstyle-0548.png",
              "mstyle-0252.png",
              "mstyle-0261.png",
              "mstyle-0597.png",
              "mstyle-0344.png",
              "mstyle-0329.png",
              "mstyle-0161.png",
              "mstyle-0295.png",
              "mstyle-0581.png",
              "mstyle-0153.png",
              "mstyle-0717.png",
              "mstyle-0182.png",
              "mstyle-0212.png",
              "mstyle-0476.png",
              "mstyle-0061.png",
              "mstyle-0621.png",
              "mstyle-0467.png",
              "mstyle-0565.png",
              "mstyle-0472.png",
              "mstyle-0640.png",
              "mstyle-0382.png",
              "mstyle-0675.png",
              "mstyle-0673.png",
              "mstyle-0013.png",
              "mstyle-0339.png",
              "mstyle-0453.png",
              "mstyle-0661.png",
              "mstyle-0586.png",
              "mstyle-0285.png",
              "mstyle-0070.png",
              "mstyle-0356.png",
              "mstyle-0049.png",
              "mstyle-0639.png",
              "mstyle-0077.png",
              "mstyle-0622.png",
              "mstyle-0203.png",
              "mstyle-0416.png",
              "mstyle-0530.png",
              "mstyle-0490.png",
              "mstyle-0564.png",
              "mstyle-0368.png",
              "mstyle-0607.png",
              "mstyle-0073.png",
              "mstyle-0225.png",
              "mstyle-0021.png",
              "mstyle-0123.png",
              "mstyle-0096.png",
              "mstyle-0500.png",
              "mstyle-0704.png",
              "mstyle-0267.png",
              "mstyle-0486.png",
              "mstyle-0136.png",
              "mstyle-0343.png",
              "mstyle-0048.png",
              "mstyle-0327.png",
              "mstyle-0348.png",
              "mstyle-0407.png",
              "mstyle-0498.png",
              "mstyle-0479.png",
              "mstyle-0503.png",
              "mstyle-0311.png",
              "mstyle-0316.png",
              "mstyle-0514.png",
              "mstyle-0132.png",
              "mstyle-0598.png",
              "mstyle-0542.png",
              "mstyle-0271.png",
              "mstyle-0408.png",
              "mstyle-0178.png",
              "mstyle-0397.png",
              "mstyle-0623.png",
              "mstyle-0244.png",
              "mstyle-0210.png",
              "mstyle-0093.png",
              "mstyle-0653.png",
              "mstyle-0331.png",
              "mstyle-0392.png",
              "mstyle-0554.png",
              "mstyle-0330.png",
              "mstyle-0662.png",
              "mstyle-0094.png",
              "mstyle-0615.png",
              "mstyle-0292.png",
              "mstyle-0451.png",
              "mstyle-0706.png",
              "mstyle-0701.png",
              "mstyle-0083.png",
              "mstyle-0027.png",
              "mstyle-0645.png",
              "mstyle-0547.png",
              "mstyle-0431.png",
              "mstyle-0618.png",
              "mstyle-0167.png",
              "mstyle-0059.png",
              "mstyle-0433.png",
              "mstyle-0091.png",
              "mstyle-0699.png",
              "mstyle-0634.png",
              "mstyle-0054.png",
              "mstyle-0188.png",
              "mstyle-0003.png",
              "mstyle-0676.png",
              "mstyle-0367.png",
              "mstyle-0240.png",
              "mstyle-0207.png",
              "mstyle-0494.png",
              "mstyle-0698.png",
              "mstyle-0232.png",
              "mstyle-0477.png",
              "mstyle-0338.png",
              "mstyle-0422.png",
              "mstyle-0326.png",
              "mstyle-0355.png",
              "mstyle-0143.png",
              "mstyle-0549.png",
              "mstyle-0571.png",
              "mstyle-0458.png",
              "mstyle-0283.png",
              "mstyle-0466.png",
              "mstyle-0394.png",
              "mstyle-0038.png",
              "mstyle-0666.png",
              "mstyle-0384.png",
              "mstyle-0320.png",
              "mstyle-0526.png",
              "mstyle-0127.png",
              "mstyle-0630.png",
              "mstyle-0660.png",
              "mstyle-0465.png",
              "mstyle-0097.png",
              "mstyle-0081.png",
              "mstyle-0030.png",
              "mstyle-0413.png",
              "mstyle-0234.png",
              "mstyle-0160.png",
              "mstyle-0674.png",
              "mstyle-0053.png",
              "mstyle-0220.png",
              "mstyle-0628.png",
              "mstyle-0489.png",
              "mstyle-0651.png",
              "mstyle-0570.png",
              "mstyle-0036.png",
              "mstyle-0383.png",
              "mstyle-0196.png",
              "mstyle-0584.png",
              "mstyle-0202.png",
              "mstyle-0424.png",
              "mstyle-0047.png",
              "mstyle-0406.png",
              "mstyle-0648.png",
              "mstyle-0287.png",
              "mstyle-0194.png",
              "mstyle-0274.png",
              "mstyle-0636.png",
              "mstyle-0434.png",
              "mstyle-0594.png",
              "mstyle-0444.png",
              "mstyle-0086.png",
              "mstyle-0352.png",
              "mstyle-0130.png",
              "mstyle-0609.png",
              "mstyle-0302.png",
              "mstyle-0591.png",
              "mstyle-0333.png",
              "mstyle-0375.png",
              "mstyle-0205.png",
              "mstyle-0278.png",
              "mstyle-0446.png",
              "mstyle-0401.png",
              "mstyle-0430.png",
              "mstyle-0289.png",
              "mstyle-0158.png",
              "mstyle-0423.png",
              "mstyle-0583.png",
              "mstyle-0617.png",
              "mstyle-0014.png",
              "mstyle-0683.png",
              "mstyle-0664.png",
              "mstyle-0411.png",
              "mstyle-0558.png",
              "mstyle-0310.png",
              "mstyle-0255.png",
              "mstyle-0151.png",
              "mstyle-0537.png",
              "mstyle-0216.png",
              "mstyle-0557.png",
              "mstyle-0057.png",
              "mstyle-0011.png",
              "mstyle-0002.png",
              "mstyle-0259.png",
              "mstyle-0346.png",
              "mstyle-0015.png",
              "mstyle-0499.png",
              "mstyle-0023.png",
              "mstyle-0575.png",
              "mstyle-0078.png",
              "mstyle-0562.png",
              "mstyle-0538.png",
              "mstyle-0637.png",
              "mstyle-0559.png",
              "mstyle-0612.png",
              "mstyle-0020.png",
              "mstyle-0181.png",
              "mstyle-0553.png",
              "mstyle-0391.png",
              "mstyle-0233.png",
              "mstyle-0619.png",
              "mstyle-0568.png",
              "mstyle-0155.png",
              "mstyle-0288.png",
              "mstyle-0303.png",
              "mstyle-0668.png",
              "mstyle-0681.png",
              "mstyle-0560.png",
              "mstyle-0275.png",
              "mstyle-0626.png",
              "mstyle-0273.png",
              "mstyle-0213.png",
              "mstyle-0516.png",
              "mstyle-0195.png",
              "mstyle-0643.png",
              "mstyle-0697.png",
              "mstyle-0603.png",
              "mstyle-0512.png",
              "mstyle-0111.png",
              "mstyle-0174.png",
              "mstyle-0122.png",
              "mstyle-0184.png",
              "mstyle-0613.png",
              "mstyle-0655.png",
              "mstyle-0369.png",
              "mstyle-0175.png",
              "mstyle-0258.png",
              "mstyle-0103.png",
              "mstyle-0224.png",
              "mstyle-0518.png",
              "mstyle-0139.png",
              "mstyle-0373.png",
              "mstyle-0633.png",
              "mstyle-0262.png",
              "mstyle-0089.png",
              "mstyle-0606.png",
              "mstyle-0214.png",
              "mstyle-0243.png",
              "mstyle-0051.png",
              "mstyle-0010.png",
              "mstyle-0157.png",
              "mstyle-0341.png",
              "mstyle-0208.png",
              "mstyle-0191.png",
              "mstyle-0170.png",
              "mstyle-0372.png",
              "mstyle-0249.png",
              "mstyle-0281.png",
              "mstyle-0400.png",
              "mstyle-0497.png",
              "mstyle-0131.png",
              "mstyle-0524.png",
              "mstyle-0652.png",
              "mstyle-0351.png",
              "mstyle-0555.png",
              "mstyle-0154.png",
              "mstyle-0445.png",
              "mstyle-0114.png",
              "mstyle-0646.png",
              "mstyle-0177.png",
              "mstyle-0441.png",
              "mstyle-0129.png",
              "mstyle-0693.png",
              "mstyle-0579.png",
              "mstyle-0263.png",
              "mstyle-0109.png",
              "mstyle-0362.png",
              "mstyle-0418.png",
              "mstyle-0687.png",
              "mstyle-0404.png",
              "mstyle-0363.png",
              "mstyle-0211.png",
              "mstyle-0657.png",
              "mstyle-0140.png",
              "mstyle-0425.png",
              "mstyle-0389.png",
              "mstyle-0678.png",
              "mstyle-0334.png",
              "mstyle-0299.png",
              "mstyle-0449.png",
              "mstyle-0426.png",
              "mstyle-0502.png",
              "mstyle-0461.png",
              "mstyle-0024.png",
              "mstyle-0313.png",
              "mstyle-0173.png",
              "mstyle-0176.png",
              "mstyle-0688.png",
              "mstyle-0237.png",
              "mstyle-0230.png",
              "mstyle-0084.png",
              "mstyle-0713.png",
              "mstyle-0169.png",
              "mstyle-0627.png",
              "mstyle-0228.png",
              "mstyle-0033.png",
              "mstyle-0226.png",
              "mstyle-0672.png",
              "mstyle-0533.png",
              "mstyle-0250.png",
              "mstyle-0432.png",
              "mstyle-0616.png",
              "mstyle-0147.png",
              "mstyle-0459.png",
              "mstyle-0165.png",
              "mstyle-0260.png",
              "mstyle-0064.png",
              "mstyle-0257.png",
              "mstyle-0483.png",
              "mstyle-0186.png",
              "mstyle-0264.png",
              "mstyle-0379.png",
              "mstyle-0531.png",
              "mstyle-0332.png",
              "mstyle-0574.png",
              "mstyle-0715.png",
              "mstyle-0229.png",
              "mstyle-0385.png",
              "mstyle-0306.png",
              "mstyle-0658.png",
              "mstyle-0691.png",
              "mstyle-0215.png",
              "mstyle-0090.png",
              "mstyle-0179.png",
              "mstyle-0470.png",
              "mstyle-0019.png",
              "mstyle-0100.png",
              "mstyle-0702.png",
              "mstyle-0718.png",
              "mstyle-0602.png",
              "mstyle-0137.png",
              "mstyle-0324.png",
              "mstyle-0134.png",
              "mstyle-0087.png",
              "mstyle-0116.png",
              "mstyle-0644.png",
              "mstyle-0276.png",
              "mstyle-0649.png",
              "mstyle-0242.png",
              "mstyle-0071.png",
              "mstyle-0550.png",
              "mstyle-0026.png",
              "mstyle-0692.png",
              "mstyle-0128.png",
              "mstyle-0712.png",
              "mstyle-0005.png",
              "mstyle-0665.png",
              "mstyle-0085.png",
              "mstyle-0519.png",
              "mstyle-0532.png",
              "mstyle-0115.png",
              "mstyle-0337.png",
              "mstyle-0308.png",
              "mstyle-0527.png",
              "mstyle-0496.png",
              "mstyle-0004.png",
              "mstyle-0323.png",
              "mstyle-0006.png",
              "mstyle-0534.png",
              "mstyle-0068.png",
              "mstyle-0457.png",
              "mstyle-0601.png",
              "mstyle-0386.png",
              "mstyle-0358.png",
              "mstyle-0543.png",
              "mstyle-0197.png",
              "mstyle-0366.png",
              "mstyle-0540.png",
              "mstyle-0110.png",
              "mstyle-0166.png",
              "mstyle-0017.png",
              "mstyle-0440.png",
              "mstyle-0042.png",
              "mstyle-0159.png",
              "mstyle-0682.png",
              "mstyle-0101.png",
              "mstyle-0062.png",
              "mstyle-0265.png",
              "mstyle-0456.png",
              "mstyle-0443.png",
              "mstyle-0035.png",
              "mstyle-0293.png",
              "mstyle-0566.png",
              "mstyle-00104.png",
              "mstyle-0696.png",
              "mstyle-0721.png",
              "mstyle-0545.png",
              "mstyle-0231.png",
              "mstyle-0686.png",
              "mstyle-0286.png",
              "mstyle-0436.png",
              "mstyle-0039.png",
              "mstyle-0371.png",
              "mstyle-0321.png",
              "mstyle-0632.png",
              "mstyle-0056.png",
              "mstyle-0421.png",
              "mstyle-0209.png",
              "mstyle-0198.png",
              "mstyle-0221.png",
              "mstyle-0522.png",
              "mstyle-0708.png",
              "mstyle-0631.png",
              "mstyle-0079.png",
              "mstyle-0420.png",
              "mstyle-0314.png",
              "mstyle-0254.png",
              "mstyle-0506.png",
              "mstyle-0162.png",
              "mstyle-0025.png",
              "mstyle-0473.png",
              "mstyle-0513.png",
              "mstyle-0659.png",
              "mstyle-0462.png",
              "mstyle-0223.png",
              "mstyle-0312.png",
              "mstyle-0075.png",
              "mstyle-0447.png",
              "mstyle-0190.png",
              "mstyle-0204.png",
              "mstyle-0012.png",
              "mstyle-0608.png",
              "mstyle-0359.png",
              "mstyle-0364.png",
              "mstyle-0667.png",
              "mstyle-0246.png",
              "mstyle-0417.png",
              "mstyle-0106.png",
              "mstyle-0435.png",
              "mstyle-0280.png",
              "mstyle-0709.png",
              "mstyle-0149.png",
              "mstyle-0492.png",
              "mstyle-0199.png",
              "mstyle-0361.png",
              "mstyle-0507.png",
              "mstyle-0360.png",
              "mstyle-0556.png",
              "mstyle-0567.png",
              "mstyle-0685.png",
              "mstyle-0442.png",
              "mstyle-0144.png",
              "mstyle-0474.png",
              "mstyle-0605.png",
              "mstyle-0551.png",
              "mstyle-0050.png",
              "mstyle-0365.png",
              "mstyle-0168.png",
              "mstyle-0488.png",
              "mstyle-0409.png",
              "mstyle-0135.png",
              "mstyle-0034.png",
              "mstyle-0428.png",
              "mstyle-0380.png",
              "mstyle-0481.png",
              "mstyle-0095.png",
              "mstyle-0037.png",
              "mstyle-0593.png",
              "mstyle-0405.png",
              "mstyle-0354.png",
              "mstyle-0236.png",
              "mstyle-0148.png",
              "mstyle-0282.png",
              "mstyle-0044.png",
              "mstyle-0578.png",
              "mstyle-0680.png",
              "mstyle-0590.png",
              "mstyle-0429.png",
              "mstyle-0587.png",
              "mstyle-0511.png",
              "mstyle-0544.png",
              "mstyle-0504.png",
              "mstyle-0219.png",
              "mstyle-0454.png",
              "mstyle-0248.png",
              "mstyle-0126.png",
              "mstyle-0031.png",
              "mstyle-0529.png",
              "mstyle-0599.png",
              "mstyle-0669.png",
              "mstyle-0647.png",
              "mstyle-0495.png",
              "mstyle-0569.png",
              "mstyle-0029.png",
              "mstyle-0349.png",
              "mstyle-0076.png",
              "mstyle-0475.png",
              "mstyle-0098.png",
              "mstyle-0235.png",
              "mstyle-0388.png",
              "mstyle-0582.png",
              "mstyle-0072.png",
              "mstyle-0298.png",
              "mstyle-0319.png",
              "mstyle-0510.png",
              "mstyle-0296.png",
              "mstyle-0410.png",
              "mstyle-0082.png",
              "mstyle-0080.png",
              "mstyle-0247.png",
              "mstyle-0398.png",
              "mstyle-0625.png",
              "mstyle-0620.png",
              "mstyle-0480.png",
              "mstyle-0253.png",
              "mstyle-0520.png",
              "mstyle-0309.png",
              "mstyle-0671.png",
              "mstyle-0580.png",
              "mstyle-0641.png",
              "mstyle-0376.png",
              "mstyle-0206.png",
              "mstyle-0045.png",
              "mstyle-0172.png",
              "mstyle-0381.png",
              "mstyle-0065.png",
              "mstyle-0350.png",
              "mstyle-0484.png",
              "mstyle-0141.png",
              "mstyle-0164.png",
              "mstyle-0290.png",
              "mstyle-0022.png",
              "mstyle-0315.png",
              "mstyle-0268.png",
              "mstyle-0342.png",
              "mstyle-0192.png",
              "mstyle-0561.png",
              "mstyle-0052.png",
              "mstyle-0604.png",
              "mstyle-0328.png",
              "mstyle-0001.png",
              "mstyle-0189.png",
              "mstyle-0150.png",
              "mstyle-0482.png",
              "mstyle-0307.png",
              "mstyle-0695.png",
              "mstyle-0487.png",
              "mstyle-0635.png",
              "mstyle-0387.png",
              "mstyle-0399.png",
              "mstyle-0546.png",
              "mstyle-0528.png",
              "mstyle-0638.png",
              "mstyle-0113.png",
              "mstyle-0719.png",
              "mstyle-0291.png",
              "mstyle-0227.png",
              "mstyle-0032.png",
              "mstyle-0040.png",
              "mstyle-0156.png",
              "mstyle-0463.png",
              "mstyle-0256.png",
              "mstyle-0515.png",
              "mstyle-0491.png",
              "mstyle-0353.png",
              "mstyle-0703.png",
              "mstyle-0508.png",
              "mstyle-0217.png",
              "mstyle-0374.png",
              "mstyle-0340.png",
              "mstyle-0193.png",
              "mstyle-0415.png",
              "mstyle-0245.png",
              "mstyle-0009.png",
              "mstyle-0663.png",
              "mstyle-0284.png",
              "mstyle-0427.png",
              "mstyle-0448.png",
              "mstyle-0452.png",
              "mstyle-0694.png",
              "mstyle-0305.png",
              "mstyle-0585.png",
              "mstyle-0335.png",
              "mstyle-0277.png",
              "mstyle-0007.png",
              "mstyle-0163.png",
              "mstyle-0060.png",
              "mstyle-0063.png",
              "mstyle-0460.png",
              "mstyle-0055.png",
              "mstyle-0041.png",
              "mstyle-0521.png",
              "mstyle-0670.png",
              "mstyle-0396.png",
              "mstyle-0525.png",
              "mstyle-0138.png",
              "mstyle-0088.png",
              "mstyle-0650.png",
              "mstyle-0572.png",
              "mstyle-0304.png",
              "mstyle-0437.png",
              "mstyle-0142.png",
              "mstyle-0610.png",
              "mstyle-0464.png",
              "mstyle-0058.png",
              "mstyle-0614.png",
              "mstyle-0679.png",
              "mstyle-0588.png",
              "mstyle-0124.png",
              "mstyle-0043.png",
              "mstyle-0294.png",
              "mstyle-0689.png",
              "mstyle-0269.png",
              "mstyle-0377.png",
              "mstyle-0624.png",
              "mstyle-0279.png",
              "mstyle-0654.png",
              "mstyle-0018.png",
              "mstyle-0523.png",
              "mstyle-0318.png",
              "mstyle-0300.png",
              "mstyle-0414.png",
              "mstyle-0066.png",
              "mstyle-0493.png",
              "mstyle-0187.png",
              "mstyle-0705.png",
              "mstyle-0028.png",
              "mstyle-0710.png"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "SelectView",
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "index": 323,
            "layout": "IPY_MODEL_8128c5e87ae14566a280a8f42f4d161c",
            "rows": 25,
            "style": "IPY_MODEL_3e7591611fc24547a2cf425ea3535518"
          }
        },
        "6c799f0085124daea6caaeaf5663873b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_fc94b23c6b4f4bb9b310f012906f3f98",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "VBox(children=(HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x…",
                  "application/vnd.jupyter.widget-view+json": {
                    "version_major": 2,
                    "version_minor": 0,
                    "model_id": "1fbf0748bf6f4e5c91d76a126bf20524"
                  }
                },
                "metadata": {}
              }
            ]
          }
        },
        "42e771e595264165b55c50649e2220a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8128c5e87ae14566a280a8f42f4d161c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e7591611fc24547a2cf425ea3535518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc94b23c6b4f4bb9b310f012906f3f98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fbf0748bf6f4e5c91d76a126bf20524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c1c239ee37945aca6d13603db342dc6"
            ],
            "layout": "IPY_MODEL_8f8454aad91849c7a9b6f48dc11feb50"
          }
        },
        "7c1c239ee37945aca6d13603db342dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22952f1215544894a26b432c2e6e1938",
              "IPY_MODEL_8be8320ec1ce4e13948da5be8960fc43",
              "IPY_MODEL_15353aa966ed42a488be72cf492126ae"
            ],
            "layout": "IPY_MODEL_86f5167171954257839f072f76c6af03"
          }
        },
        "8f8454aad91849c7a9b6f48dc11feb50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22952f1215544894a26b432c2e6e1938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "png",
            "height": "420",
            "layout": "IPY_MODEL_d68e8e0856f64ddb8d0127655303dce2",
            "width": "420"
          }
        },
        "8be8320ec1ce4e13948da5be8960fc43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_87de9d3a49f545758839639b715f3427",
            "placeholder": "​",
            "rows": null,
            "style": "IPY_MODEL_b7203004fa6f4037aff09238b1e02b92",
            "value": "A photograph of a wooden boat gently gliding across a serene lake, with a romantic and dreamy mood, captured at sunrise with a digital mirrorless camera and a wide-angle lens"
          }
        },
        "15353aa966ed42a488be72cf492126ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Save",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ebe762e1d8d844a4b9bb991b7c6d0baa",
            "style": "IPY_MODEL_fe97ec72454b4f8f910cbc4fbefbed5f",
            "tooltip": ""
          }
        },
        "86f5167171954257839f072f76c6af03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d68e8e0856f64ddb8d0127655303dce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87de9d3a49f545758839639b715f3427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "120px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "300px"
          }
        },
        "b7203004fa6f4037aff09238b1e02b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebe762e1d8d844a4b9bb991b7c6d0baa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe97ec72454b4f8f910cbc4fbefbed5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}